#权威性指标调研
## update 3.30
之前方案：UBS构造一个一般项目的基于search的权威性评价指标。
NOW: 和时效性类似

* 指标目的是进行权威性监控，防止其他实验权威性指标过差
	* maxiao的权威性模型对每个url会计算一个score，然后计算dcg
* KPI 进行权威性人工评估
	* 要加到绝对收益里？？

Q:  

* maxiao authority模型的准确性问题
* 同样需要在人工评估集合上验证
* 不太好回归实验
* 整体方向与大小，case级别准确率

![](media/14603024157997/14716964184192.jpg)



### 时效性：
* 泛时效，随机抽取habo，然后进行分类。
百度+2竞品
* 突发：是钱祺那边跑 新闻title切词+querylog 再过人工
	* 每季度前两个月50Q  第三个月100Q  都是9个时段 PC一个竞品 一个季度一评
	* wise月级  2个竞品

## 背景
 对于大搜来说，衡量搜索结果的好坏主要是从相关性、时效性、页面质量等维度去判断。权威性指标主要用来衡量搜索结果的权威性，即当用户输入一个query之后，返回的结果页面的权威性程度。
关于权威性的定义，这里说的权威性是一个广义的概念，参考权威性人工评估的标准，主要包括以下几个方面：

* 网站知名度： 大站 TF
* 可信(官方)：
	* 官网, gov, edu.
	* 寻址类.
* 专业领域： query分类===> 主题. IDF
* 原创类

对于权威性的评估，首先需要识别出权威性需求的query，然后针对策略和基线的展示结果，给予一个权威性效果的打分。

## 评估思路
首先用户每次输入的query并不一定都是权威性需求query，对于一般的输入query，可以考虑下基于url角度的扩大更多召回。
 对于有权威性需求的query，根据我们构造的权威性词典，若其命中其中的term，则将其展现结果与该query下的top_url_list做对比，根据该query下url的不同得分结合展示的位置等信息进行权威性打分，整个指标评估流程示意图如下：
#### 添加图


算法1.0具体步骤如下
### 1. 构造权威性词典eval_dict
* 基于刘峰团队的term-site的一个top url排名，每一个term下有对应的按照置信度排名的url list
* query分类的一般化的词典
后面实验发现有时候无法命中query，或者命中query后url不在词典的url list中。对于一些大站、好的站点就比较吃亏。所以需要构造一个一般化的按照query分类的比如基于TF-IDF的词典
* liuchao挖掘的url list

note: 上面(2),(3)还未添加

### 2.query切分term，从eval_dict中找到match term
* 对每次search下的query进行term切分，切分方法选择的是basic和pharse，得到term1_list, term2_list.
* 将两个list进行预处理合并得到term_list
	* 长度<2的抛弃
	* 重复的抛弃
	* 真包含的抛弃
* 将该query下的term_list中每一个term与eval_dict词典进行相似度匹配

```
if term or query in eval_dict:
    return match的term或query
else:
     计算query与eval_dcit中每个term的相似性
     # new_simple_match
     rr=|A交B|/|A并B|
     if rr > rr_threshold:
         return match term以及rr
```
* 得到最终匹配的final_match_term_dict

note：
### 3构建merge url list
匹配上的每一个$term_i$，都对应着一个$(termlist_i, 相似度rr)$

* 将$termlist_i$中的第j个url的置信值$val_{ij}$先进行变换
$$tmp.val_{ij}=log(val_{ij}+1)*rr$$
记$MAX=max(tmp.val_{ij})$, $MIN=min(tmp.val_{ij})$
* 归一化：
	* ~~[0,1]最大，最小值，会出现始终有0的与未匹配的区分不出~~
	* now:

  ```
if MAX>MIN:
	final_val=tmp_val/MAX
else:
	final_val= 1/len(val_list)
	```
	
* 若同一个url存在不同的termlist中，取最大的final_val。最终输出
 merge_top_dict[url]=final_val

### 4.计算score
* 得到策略和基线有diff的pos_list

```
for pos in diff_list:
    val_a=val_b=0
    if url1 or url2 in merge_top_dict:
        get val_a,val_b
    pos_ascore=val_a/pos, pos_bscore=val_b/pos
ascore=sum(pos_ascore), bscore=sum(pos_bscore)
``` 
* 汇总所有search，计算平均score


## V.0 效果验证+case分析

以人工标注的200个权威性样本为评估集合：
整体200query中： match上query有169，命中率84.5%

* match上query且命中url有67个，命中率39.6%
	* 67个中27个判断完全一致，5个正负相反
	* 40个误判case原因：
		* 22个url一边未命中，其中19个真实打分是0，打分需要设置阈值？？
		* 3个词典问题，逆序
		* 3 算法相似性问题，对英文字符，符号的处理
		* 5 同domain站点，人工评估一般持平。算法
		* baike等结果赋值？
	* **整体上感觉，算法在判断具体case的score正负值比人工的-1，0，1打分要敏感，需要设置些平滑些的阈值处理**

* 两边完全未命中url的有102
	* 模型判断是0，真实的GSB=27:57:18


# to do

* 马骁 new_score方法在200case上实验效果

s1: 当前词典回归

* fix词典中的问题
* 修改算法中的小问题：
	* 相似性
	* 。。。 
* 词典是否需要重新切分term
 
s2. 回归实验===> 设置阈值

s3:构造新的词典

	* dfs://szwg-stoff-hdfs.dmop.baidu.com:54310/app/ps/rank/factor/yangxuan/top_10_term_result 
	yangxuan，基于term的保留前10，不同term不可比
	* 之前mining的结果 `/ps/ubs/kce/zhenzhen/authority/mining_out`
	* 智慧，更多人工评估的case ？？






 

